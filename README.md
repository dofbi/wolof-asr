# Wolof ASR Training with OpenAI Whisper

Ce dÃ©pÃ´t contient le code, la documentation et les modÃ¨les gÃ©nÃ©rÃ©s pour entraÃ®ner un systÃ¨me de **Reconnaissance Automatique de la Parole (ASR)** en wolof, en utilisant le modÃ¨le **OpenAI Whisper** et les donnÃ©es du dataset [Wolof TTS](https://huggingface.co/datasets/galsenai/wolof_tts).

## ğŸš€ Objectif du projet

L'objectif de ce projet est de crÃ©er un modÃ¨le performant pour la reconnaissance vocale automatique (ASR) en wolof, une langue africaine largement parlÃ©e au SÃ©nÃ©gal. Ce projet vise Ã  :
- DÃ©velopper une **solution robuste** pour la transcription audio-texte en wolof.
- Contribuer Ã  la prÃ©servation et Ã  la valorisation des langues africaines Ã  travers des outils technologiques.
- Faciliter l'intÃ©gration des systÃ¨mes ASR dans des applications locales.

---

## ğŸ“š Dataset

Le projet utilise le dataset public suivant :
- **[Wolof TTS](https://huggingface.co/datasets/galsenai/wolof_tts)** : un corpus contenant des donnÃ©es audios et leurs transcriptions en wolof.

### PrÃ©paration des donnÃ©es
Les donnÃ©es sont automatiquement tÃ©lÃ©chargÃ©es et traitÃ©es pour Ãªtre utilisÃ©es dans le pipeline d'entraÃ®nement. Le script convertit le format des fichiers pour qu'ils soient compatibles avec le modÃ¨le **Whisper**.

---

## ğŸ—ï¸ Structure du projet

Voici la structure principale du dÃ©pÃ´t :

```
.
â”œâ”€â”€ data/                          # Dossier contenant les donnÃ©es d'entrÃ©e et prÃ©-traitÃ©es
â”œâ”€â”€ src/                           # Code source
â”‚   â”œâ”€â”€ dataset_loader.py          # Script pour charger et prÃ©parer le dataset
â”‚   â”œâ”€â”€ training.py                # Script d'entraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ evaluation.py              # Script d'Ã©valuation
â”‚   â”œâ”€â”€ utils.py                   # Fonctions utilitaires
â”œâ”€â”€ models/                        # Dossier pour stocker les modÃ¨les gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ experiment_0/
â”‚   â”‚   â”œâ”€â”€ checkpoints/           # Sauvegardes des epochs
â”‚   â”‚   â””â”€â”€ final_model.pt         # ModÃ¨le final entraÃ®nÃ©
â”œâ”€â”€ README.md                      # Documentation du projet
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â””â”€â”€ config.yaml                    # Fichier de configuration du projet
```

---

## ğŸ› ï¸ EntraÃ®nement

### Ã‰tapes pour exÃ©cuter le projet :

1. **Cloner le dÃ©pÃ´t** :
   ```bash
   git clone https://github.com/votre-utilisateur/wolof-asr.git
   cd wolof-asr
   ```

2. **Installer les dÃ©pendances** :
   CrÃ©ez un environnement virtuel (optionnel mais recommandÃ©) :
   ```bash
   python3 -m venv env
   source env/bin/activate
   pip install -r requirements.txt
   ```

3. **Configurer les paramÃ¨tres** :
   Modifiez le fichier `config.yaml` pour ajuster les hyperparamÃ¨tres tels que :
   - Nombre d'Ã©poques
   - Taille du batch
   - Learning rate

4. **Lancer l'entraÃ®nement** :
   ExÃ©cutez le script d'entraÃ®nement :
   ```bash
   python app.py
   ```

5. **Suivi en temps rÃ©el avec Weights & Biases** :
   Connectez-vous Ã  votre compte **Weights & Biases** pour surveiller les mÃ©triques.

---

## ğŸ“Š Ã‰valuation

AprÃ¨s l'entraÃ®nement, Ã©valuez le modÃ¨le sur un dataset de test pour calculer des mÃ©triques comme :
- **WER (Word Error Rate)** : mesure de prÃ©cision de la transcription.
- **CER (Character Error Rate)** : pour des transcriptions plus granulaires.

ExÃ©cutez :
```bash
python src/evaluation.py --model_path=models/experiment_0/final_model.pt
```

---

## ğŸ“‚ ModÃ¨les gÃ©nÃ©rÃ©s

### ModÃ¨les disponibles
| ModÃ¨le            | Taille     | Architecture            | Lien                                                                                  |
|--------------------|------------|--------------------------|---------------------------------------------------------------------------------------|
| Whisper-Wolof-Small | ~240M      | `openai/whisper-small`   | [TÃ©lÃ©charger](https://huggingface.co/)                   |
| Whisper-Wolof-Tiny | ~75M       | `openai/whisper-tiny`    | [TÃ©lÃ©charger](https://huggingface.co/)                    |

---

## ğŸ™Œ Contributeurs

Nous remercions les contributeurs pour leur travail et leur engagement dans ce projet.

- **[Mamadou Diagne](https://github.com/dofbi)** - DÃ©veloppeur principal
- **[Nom du contributeur](https://github.com/contributeur)** - Support technique
- **[GalsenAI](https://huggingface.co/galsenai)** - Fournisseur du dataset

Si vous souhaitez contribuer, merci de soumettre une *Pull Request* ou de contacter [votre email].

---

## ğŸ“œ Licence

Ce projet est sous licence **MIT**. Vous Ãªtes libre d'utiliser, de modifier et de distribuer le code, sous rÃ©serve de mentionner les auteurs originaux.

---

## ğŸŒ Impact attendu

Ce projet constitue une avancÃ©e technologique majeure pour la numÃ©risation des langues africaines, avec des applications possibles dans l'Ã©ducation, les technologies vocales et la prÃ©servation culturelle.
